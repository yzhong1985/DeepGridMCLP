{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bba16fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'problems'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproblems\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMCLP\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproblem_MCLP\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MCLP   \u001b[38;5;66;03m# Make sure to import from the correct module\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionModel  \u001b[38;5;66;03m# Adjust the import based on your model definition\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m move_to, load_problem, load_args  \u001b[38;5;66;03m# Import necessary helper functions\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'problems'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from problems.MCLP.problem_MCLP import MCLP   # Make sure to import from the correct module\n",
    "from nets.attention_model import AttentionModel  # Adjust the import based on your model definition\n",
    "from utils import move_to, load_problem, load_args  # Import necessary helper functions\n",
    "from options import get_options\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5cf701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: -543.2852, Log-Likelihood: -34.1953\n",
      "Cost: -377.4672, Log-Likelihood: -30.6571\n",
      "Cost: -408.5402, Log-Likelihood: -23.5819\n",
      "Cost: -372.0929, Log-Likelihood: -33.5401\n",
      "Cost: -584.3042, Log-Likelihood: -33.9011\n",
      "Cost: -549.9301, Log-Likelihood: -25.8412\n",
      "Cost: -509.6411, Log-Likelihood: -27.8715\n",
      "Cost: -351.6451, Log-Likelihood: -37.8440\n",
      "Cost: -417.0859, Log-Likelihood: -34.9446\n",
      "Cost: -439.0831, Log-Likelihood: -26.9170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Set up the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "opts = {\n",
    "    \"problem\": \"MCLP\",\n",
    "    \"n_users\": 500,\n",
    "    \"n_facilities\": 150,\n",
    "    \"p\": 20,\n",
    "    \"r\": 0.05,\n",
    "    \"batch_size\": 640,\n",
    "    \"epoch_size\": 128000,\n",
    "    \"val_size\": 2000,\n",
    "    \"val_dataset\": None,\n",
    "    \"model\": \"attention\",\n",
    "    \"embedding_dim\": 128,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"n_encode_layers\": 3,\n",
    "    \"tanh_clipping\": 10.0,\n",
    "    \"normalization\": \"batch\",\n",
    "    \"lr_model\": 0.0001,\n",
    "    \"lr_critic\": 0.0001,\n",
    "    \"lr_decay\": 1,\n",
    "    \"eval_only\": False,\n",
    "    \"n_epochs\": 200,\n",
    "    \"seed\": 2024,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"exp_beta\": 0.8,\n",
    "    \"baseline\": None,\n",
    "    \"bl_alpha\": 0.05,\n",
    "    \"bl_warmup_epochs\": 0,\n",
    "    \"eval_batch_size\": 1000,\n",
    "    \"checkpoint_encoder\": False,\n",
    "    \"shrink_size\": None,\n",
    "    \"data_distribution\": None,\n",
    "    \"log_step\": 50,\n",
    "    \"log_dir\": \"logs\",\n",
    "    \"run_name\": \"500_150_20_20241005T184518\",\n",
    "    \"output_dir\": \"outputs\",\n",
    "    \"epoch_start\": 0,\n",
    "    \"checkpoint_epochs\": 1,\n",
    "    \"load_path\": None,\n",
    "    \"resume\": None,\n",
    "    \"no_tensorboard\": False,\n",
    "    \"no_progress_bar\": False,\n",
    "    \"use_cuda\": True,\n",
    "    \"save_dir\": \"outputs\\\\MCLP\\\\500_150_20_20241005T184518\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Load the saved model (e.g., epoch-1.pt)\n",
    "model_path = 'outputs/MCLP/500_150_20_20241005T184518/epoch-199.pt'  # Adjust the path as needed\n",
    "model_data = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Rebuild the model structure\n",
    "problem = load_problem(opts['problem'])  # Use square brackets for dictionary access\n",
    "model = AttentionModel(\n",
    "    opts['embedding_dim'],\n",
    "    opts['hidden_dim'],\n",
    "    problem,\n",
    "    n_encode_layers=opts['n_encode_layers'],\n",
    "    mask_inner=True,\n",
    "    mask_logits=True,\n",
    "    normalization=opts['normalization'],\n",
    "    tanh_clipping=opts['tanh_clipping'],\n",
    "    checkpoint_encoder=opts['checkpoint_encoder'],\n",
    "    shrink_size=opts['shrink_size'],\n",
    ")\n",
    "\n",
    "# Load the model parameters\n",
    "model.load_state_dict(model_data['model'])\n",
    "model.to(device)  # Move the model to the device (GPU/CPU)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.set_decode_type(\"greedy\")\n",
    "\n",
    "# 3. Generate a random dataset\n",
    "random_dataset = MCLP.make_dataset(n_users=500, n_facilities=150, num_samples=10, p=20, r=0.05)\n",
    "\n",
    "# Use DataLoader to load the dataset\n",
    "random_dataloader = DataLoader(random_dataset, batch_size=1)\n",
    "\n",
    "for batch in random_dataloader:\n",
    "    batch = move_to(batch, device)  # Move the batch to the device (GPU/CPU)\n",
    "    \n",
    "    # Perform model inference\n",
    "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "        cost, log_likelihood = model(batch)  # Get the model's prediction (two values returned)\n",
    "        \n",
    "        # Convert tensor values to Python numbers and print them in a readable format\n",
    "        cost_value = cost.item()\n",
    "        log_likelihood_value = log_likelihood.item()\n",
    "        \n",
    "        # Print the formatted result\n",
    "        print(f\"Cost: {cost_value:.4f}, Log-Likelihood: {log_likelihood_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac95b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current top solution: [84, 80, 129, 117, 40, 23, 118, 71, 105, 120, 83, 54, 72, 33, 36, 141, 93, 128, 27, 116] f=2332\n",
      "\n",
      "Final top solution: [147, 117, 132, 46, 80, 13, 143, 21, 87, 123, 30, 145, 77, 108, 98, 103, 141, 39, 53, 49] f=2097\n",
      "Time: 00:00:0.3414\n",
      "Number of covered demand points: 115\n",
      "[729.62274]\n",
      "Current top solution: [32, 17, 93, 88, 149, 20, 138, 2, 31, 36, 80, 132, 91, 112, 26, 50, 10, 34, 116, 23] f=2421\n",
      "\n",
      "Final top solution: [142, 32, 48, 61, 26, 74, 92, 136, 132, 110, 127, 143, 116, 47, 40, 2, 106, 149, 140, 62] f=2162\n",
      "Time: 00:00:0.3326\n",
      "Number of covered demand points: 118\n",
      "[748.2204]\n",
      "Current top solution: [61, 124, 46, 81, 36, 133, 0, 121, 126, 91, 23, 60, 68, 34, 54, 65, 114, 118, 67, 30] f=2243\n",
      "\n",
      "Final top solution: [23, 117, 136, 38, 102, 10, 6, 95, 12, 56, 68, 115, 123, 128, 64, 34, 145, 22, 118, 100] f=2002\n",
      "Time: 00:00:0.3323\n",
      "Number of covered demand points: 119\n",
      "[726.6266]\n",
      "Current top solution: [126, 121, 132, 114, 28, 94, 135, 137, 27, 139, 133, 111, 118, 84, 87, 31, 60, 144, 69, 43] f=2296\n",
      "\n",
      "Final top solution: [140, 144, 139, 87, 129, 67, 113, 135, 31, 68, 79, 28, 24, 134, 47, 1, 137, 50, 3, 82] f=2074\n",
      "Time: 00:00:0.3399\n",
      "Number of covered demand points: 118\n",
      "[735.80035]\n",
      "Current top solution: [78, 48, 15, 45, 127, 81, 149, 73, 74, 50, 97, 126, 34, 89, 13, 111, 109, 134, 128, 64] f=2199\n",
      "\n",
      "Final top solution: [127, 78, 100, 38, 124, 36, 0, 50, 18, 2, 137, 145, 29, 80, 102, 76, 34, 119, 46, 81] f=1970\n",
      "Time: 00:00:0.3356\n",
      "Number of covered demand points: 130\n",
      "[791.89734]\n",
      "Current top solution: [148, 146, 142, 108, 88, 46, 58, 99, 8, 127, 63, 38, 9, 19, 73, 125, 32, 54, 117, 34] f=2289\n",
      "\n",
      "Final top solution: [136, 132, 61, 37, 51, 119, 135, 4, 110, 25, 108, 71, 144, 50, 84, 47, 107, 53, 55, 34] f=1987\n",
      "Time: 00:00:0.3361\n",
      "Number of covered demand points: 130\n",
      "[758.40564]\n",
      "Current top solution: [121, 83, 116, 66, 20, 21, 138, 42, 2, 40, 137, 94, 107, 64, 131, 34, 97, 88, 142, 11] f=2254\n",
      "\n",
      "Final top solution: [51, 75, 93, 78, 14, 95, 25, 20, 64, 1, 2, 126, 52, 8, 6, 37, 88, 11, 127, 12] f=1988\n",
      "Time: 00:00:0.3500\n",
      "Number of covered demand points: 129\n",
      "[767.77673]\n",
      "Current top solution: [6, 78, 31, 107, 72, 97, 149, 89, 10, 9, 1, 118, 135, 120, 142, 15, 109, 137, 27, 38] f=2310\n",
      "\n",
      "Final top solution: [83, 122, 50, 23, 59, 2, 137, 27, 84, 58, 89, 71, 105, 113, 115, 9, 78, 4, 74, 109] f=2126\n",
      "Time: 00:00:0.3254\n",
      "Number of covered demand points: 109\n",
      "[665.5026]\n",
      "Current top solution: [91, 136, 149, 16, 43, 102, 30, 116, 38, 120, 14, 81, 55, 70, 139, 76, 42, 19, 7, 21] f=2309\n",
      "\n",
      "Final top solution: [118, 31, 67, 124, 46, 113, 141, 91, 85, 92, 65, 130, 9, 43, 22, 70, 119, 146, 45, 102] f=1980\n",
      "Time: 00:00:0.3370\n",
      "Number of covered demand points: 136\n",
      "[832.4307]\n",
      "Current top solution: [33, 40, 108, 69, 48, 148, 65, 127, 21, 94, 113, 146, 10, 1, 133, 116, 104, 135, 141, 61] f=2233\n",
      "\n",
      "Final top solution: [25, 107, 73, 33, 135, 38, 87, 56, 30, 34, 115, 40, 94, 123, 110, 35, 74, 55, 71, 116] f=1998\n",
      "Time: 00:00:0.3289\n",
      "Number of covered demand points: 123\n",
      "[714.22327]\n"
     ]
    }
   ],
   "source": [
    "from algorithms.GA import GeneticAlgorithm\n",
    "\n",
    "def calculate_solution_objective(demand_points, demand_vals, facility_candidate_locations, radius, selected_facility_indexes):\n",
    "    covered_points = set()  \n",
    "\n",
    "    for facility_idx in selected_facility_indexes:\n",
    "        facility = facility_candidate_locations[facility_idx]  \n",
    "\n",
    "        for i, demand_point in enumerate(demand_points):\n",
    "            distance = np.linalg.norm(facility - demand_point)  \n",
    "            if distance <= radius:\n",
    "                covered_points.add(i)  \n",
    "\n",
    "    total_demand_covered = sum(demand_vals[i] for i in covered_points)\n",
    "    # Print the number of covered points\n",
    "    print(f\"Number of covered demand points: {len(covered_points)}\")\n",
    "\n",
    "    return total_demand_covered\n",
    "\n",
    "for i, batch in enumerate(random_dataloader):\n",
    "    batch = move_to(batch, device)  # Move the batch to the device (GPU/CPU)\n",
    "\n",
    "    # Extract data from the batch\n",
    "    demand_pts = batch['users'].squeeze(0).cpu().numpy()  # User demand points (numpy array)\n",
    "    demand_vals = batch['demand'].squeeze(0).cpu().numpy()  # User demand values (numpy array)\n",
    "    cls = batch['facilities'].squeeze(0).cpu().numpy()  # Candidate facility locations (numpy array)\n",
    "    r = batch['r'].item()  # Coverage radius\n",
    "    p = batch['p'].item()  # Number of facilities to select\n",
    "    \n",
    "    # 2. Calculate the distance matrix (Euclidean distance between facilities and demand points)\n",
    "    distance = np.sqrt(np.sum((cls[:, np.newaxis, :] - demand_pts[np.newaxis, :, :]) ** 2, axis=-1))\n",
    "\n",
    "    # 3. Instantiate the genetic algorithm with the necessary parameters\n",
    "    genetic = GeneticAlgorithm(len(demand_pts), len(cls), p, distance, r, demand_vals)\n",
    "\n",
    "    # 4. Run the optimization process\n",
    "    genetic.optimize()\n",
    "\n",
    "    # 5. Get the result (selected facilities and the objective value)\n",
    "    obj = np.sum(demand_vals) - genetic.top_chromosome.fitness.item()  # Ensure fitness is a scalar\n",
    "    ga_solution = genetic.top_chromosome.content  # This contains the selected facilities\n",
    "\n",
    "    # 6. Calculate the final objective value using the selected facilities from GA\n",
    "    obj_val = calculate_solution_objective(demand_pts, demand_vals, cls, r, ga_solution)\n",
    "    print(obj_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
